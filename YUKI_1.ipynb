{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPsDU79jgumj4m8pH7aKJNc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuki020936/Option-NN/blob/main/YUKI_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pip install -r requirement.txt"
      ],
      "metadata": {
        "id": "HpjWROXZbcEV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "rJ-Nw6HBRyQe",
        "outputId": "e5218716-ac04-4951-92c9-27224daf0dfc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2dc64f17e532>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0margparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgumentParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvisulization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model_avg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rapids_dask_dependency/dask_loader.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# including the internal frames, which warnings ignores).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mpatch_warning_stacklevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pyarrow_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrolling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_testing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     from dask.dataframe.core import (\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rapids_dask_dependency/dask_loader.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# including the internal frames, which warnings ignores).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mpatch_warning_stacklevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dask/dataframe/backends.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munion_categoricals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpercentile_lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_percentile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rapids_dask_dependency/dask_loader.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# including the internal frames, which warnings ignores).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mpatch_warning_stacklevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dask/array/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_overlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnanpercentile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrechunk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrechunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     from dask.array.reductions import (\n\u001b[1;32m    106\u001b[0m         \u001b[0mall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rapids_dask_dependency/dask_loader.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# including the internal frames, which warnings ignores).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mpatch_warning_stacklevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pdb #debug\n",
        "import numpy as np\n",
        "import os\n",
        "from time import sleep #sleep(?)暫停?秒\n",
        "import signal #處理訊號（signal），這些訊號是作業系統在特定情況下發送給程式的事件\n",
        "import sys\n",
        "import queue #list(q.queue)\n",
        "import shutil\n",
        "import psutil\n",
        "from multiprocessing.connection import wait\n",
        "import torch.multiprocessing as mp\n",
        "import torch\n",
        "from argparse import ArgumentParser\n",
        "from dataset import DataProcessor\n",
        "from utils import clear_files\n",
        "from visulization import plot_model_avg_loss\n",
        "import config\n",
        "from train import TrainEngine\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import time\n",
        "\n",
        "#torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "def single_running_worker():\n",
        "    try:\n",
        "        while True:\n",
        "            # run model\n",
        "            test_date, train_loss, train_mse, train_mape, train_ITMmse, train_ITMmape, train_OTMmse, train_OTMmape, test_loss, test_mse, test_mape, test_ITMmse, test_ITMmape, test_OTMmse, test_OTMmape = config.train_engine(*next(config.daily_gen)(0))\n",
        "            print(f\"date: {test_date}, train_mse: {train_mse:.3f}, train_mape: {train_mape:.3f}, test_mse: {test_mse:.3f}, test_mape: {test_mape:.3f}\",flush=True)\n",
        "            # record and update\n",
        "            for v, k in zip([test_date, train_loss, train_mse, train_mape, train_ITMmse, train_ITMmape, train_OTMmse, train_OTMmape, test_loss, test_mse, test_mape, test_ITMmse, test_ITMmape, test_OTMmse, test_OTMmape], config.model_loss_list_dict):\n",
        "                config.model_loss_list_dict[k] += [v]\n",
        "            # plot_model_avg_loss(config.result_folder, config.args.model_type, config.model_loss_list_dict)\n",
        "            end_time = time.time()\n",
        "            elapsed_time = end_time - start_time\n",
        "            hours = int(elapsed_time // 3600)\n",
        "            minutes = int((elapsed_time % 3600) // 60)\n",
        "            seconds = int(elapsed_time % 60)\n",
        "            print(f\"執行時間：{hours:02d}小時 {minutes:02d}分 {seconds:02d}秒\")\n",
        "    except StopIteration:\n",
        "        pass  # EOF of generator, fine\n",
        "\n",
        "def multi_running_check_in(rank):\n",
        "    # rank is to allocate particular device\n",
        "    # torch.distributed.init_process_group(\"nccl\", rank=rank, world_size=torch.cuda.device_count()))\n",
        "    try:\n",
        "        q = mp.Queue()\n",
        "        p = mp.Process(target=multi_running_job, args=(next(config.daily_gen)(rank), q, config.train_engine))\n",
        "    except StopIteration:\n",
        "        config.procs_info['EOF'] = True\n",
        "        return # do nothing. that is, no new process will be allocated afterwards.\n",
        "\n",
        "    # if we don't update these process info before create new child process, parent process may receive SIGCHLD signal while config.procs_info['process_fd_table'] does not include this new process. hence parent process fail to wait this child process. however, it (child process exits immediately) rarely happens.\n",
        "    p.start()\n",
        "    config.procs_info['loss_queues'].append(q)\n",
        "    config.procs_info['process_list'].append(p)\n",
        "    config.procs_info['process_fd_table'].append(p.sentinel)\n",
        "\n",
        "def multi_running_job(daily_materials, loss_queue, train_engine):\n",
        "    # register signal as we hope SIGINT signal can only be processed by parent process\n",
        "    signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
        "    # run model\n",
        "    test_date, train_loss, train_mse, train_mape, train_ITMmse, train_ITMmape, train_OTMmse, train_OTMmape, test_loss, test_mse, test_mape, test_ITMmse, test_ITMmape, test_OTMmse, test_OTMmape = train_engine(*daily_materials)\n",
        "    print(f\"[process {os.getpid()}] date: {test_date}, train_mse: {train_mse:.3f}, train_mape: {train_mape:.3f}, test_mse: {test_mse:.3f}, test_mape: {test_mape:.3f}\",flush=True)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    hours = int(elapsed_time // 3600)\n",
        "    minutes = int((elapsed_time % 3600) // 60)\n",
        "    seconds = int(elapsed_time % 60)\n",
        "    print(f\"執行時間：{hours:02d}小時 {minutes:02d}分 {seconds:02d}秒\")\n",
        "    # return results\n",
        "    loss_queue.put([train_engine.model.device, test_date, train_loss, train_mse, train_mape, train_ITMmse, train_ITMmape, train_OTMmse, train_OTMmape, test_loss, test_mse, test_mape, test_ITMmse, test_ITMmape, test_OTMmse, test_OTMmape])\n",
        "\n",
        "def sigchld_handler(signum, frame):\n",
        "    # adopt the exited child processes, collect results, identify avaliable devices\n",
        "    # since signal handler allows signal reentrancy, it may require atomic operation. but it's not safe to use lock in signal handler, refer to https://stackoverflow.com/questions/12445618/accessing-shared-data-from-a-signal-handler\n",
        "    # hence here ignore SIGCHLD signal before finishing cleaning up the process. note that new process should not be created before leaving sigchld_handler\n",
        "    # wait() will be always valid after child process status becomes exited unless pop out the process in config.procs_info['process_fd_table']\n",
        "    signal.signal(signal.SIGCHLD, signal.SIG_IGN)\n",
        "    while True:\n",
        "        p_sentns = wait(config.procs_info['process_fd_table'], 0)\n",
        "        if len(p_sentns) == 0:\n",
        "            break\n",
        "        # for each exited child process\n",
        "        for p_sentn in p_sentns:\n",
        "            # collect results\n",
        "            idx = config.procs_info['process_fd_table'].index(p_sentn)\n",
        "            # to prevent if one of the child process unexpectedly is killed and hence no results can be push into the queue, the parent process will be blocked in this line\n",
        "            try:\n",
        "                rank, test_date, *losses = config.procs_info['loss_queues'][idx].get(block=False)  # \"hang\" & Remove and return an item from the queue. If optional args block is True (the default) and timeout is None (the default), \"block\" if necessary until an item is available.\n",
        "            except queue.Empty:\n",
        "                print(\"at least one of the child process crashed, exit!\")\n",
        "                os.kill(os.getpid(), signal.SIGINT)\n",
        "            for v, k in zip([test_date]+losses, config.model_loss_list_dict):\n",
        "                config.model_loss_list_dict[k] += [v]\n",
        "\n",
        "            # update process info\n",
        "            config.procs_info['process_list'].pop(idx)\n",
        "            config.procs_info['loss_queues'].pop(idx)\n",
        "            config.procs_info['process_fd_table'].pop(idx)\n",
        "\n",
        "            # update progress bar and print results\n",
        "            plot_model_avg_loss(config.result_folder, config.args.model_type, {\n",
        "                k: [l for _, l in sorted(zip(config.model_loss_list_dict['date_list'], config.model_loss_list_dict[k]))]\n",
        "                for k in config.model_loss_list_dict.keys()})\n",
        "\n",
        "            if config.procs_info['fin_count'] % config.args.n_parallel_process == (config.args.n_parallel_process - 1) and config.procs_info['fin_count'] != 0:\n",
        "                config.progress_bar.update()\n",
        "            config.procs_info['fin_count'] = config.procs_info['fin_count'] + 1\n",
        "\n",
        "            # identify avaliable deiveces to allocate new process onto the rank which the exited process has stayed\n",
        "            config.procs_info['avaliable_device'].append(rank)\n",
        "    signal.signal(signal.SIGCHLD, sigchld_handler) # remember to reset the handler again, since we don't want to actually ignore SIGCHLD signal afterwards\n",
        "\n",
        "def sigint_handler(signum, frame):\n",
        "    # ctrl+c by user\n",
        "    # clear results in queues and terminate all the child process immediately\n",
        "    signal.signal(signal.SIGCHLD, signal.SIG_IGN)\n",
        "    print(\"catch KeyboardInterrupt, terminate all the child processes ...\")\n",
        "    for p, q in zip(config.procs_info['process_list'], config.procs_info['loss_queues']):\n",
        "        try:\n",
        "            _ = q.get(\n",
        "                block=False)  # Warning If a process is killed using Process.terminate() or os.kill() while it is trying to use a Queue, then the data in the queue is likely to become corrupted. This may cause any other process to get an exception when it tries to use the queue later on.\n",
        "        except queue.Empty:\n",
        "            pass  # fine\n",
        "        finally:\n",
        "            p.terminate()  # send SIGTERM signal to the child process\n",
        "            p.join()  # \"hang\" and adopt the child process\n",
        "            print(f\"child process {p.pid} terminated.\")\n",
        "    sys.exit(0)\n",
        "    # original_sigint_handler = signal.getsignal(signal.SIGINT)\n",
        "    # original_sigint_handler()\n",
        "\n",
        "def multi_running_worker(test_date_list):\n",
        "    # TODO: run on multiple GPUs: check the bugs related to torch.distributed.init_process_group & torch.nn.parallel.DistributedDataParallel\n",
        "    config.progress_bar = tqdm(test_date_list[::config.args.n_parallel_process])\n",
        "    config.progress_bar.reset()\n",
        "    signal.signal(signal.SIGCHLD, sigchld_handler)\n",
        "    signal.signal(signal.SIGINT, sigint_handler)\n",
        "\n",
        "    # initialize\n",
        "    for i in range(config.args.n_parallel_process):\n",
        "        multi_running_check_in(rank=i % torch.cuda.device_count() if torch.cuda.is_available() and config.args.on_gpu else -1)\n",
        "\n",
        "    while True:\n",
        "        if config.procs_info['EOF'] and len(config.procs_info['process_list']) == 0: # both conditions should be met\n",
        "            config.progress_bar.update()\n",
        "            break\n",
        "        elif len(config.procs_info['process_list']) < config.args.n_parallel_process and len(config.procs_info['avaliable_device']) > 0:\n",
        "            multi_running_check_in(rank=config.procs_info['avaliable_device'].pop(0))\n",
        "        else:\n",
        "            # suspend until receiving a signal when there still exist at least one process\n",
        "            signal.pause()\n",
        "    config.progress_bar.close()\n",
        "\n",
        "def main(start_time):\n",
        "    # ----------Hyper Parameters----------#\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument('--result_folder_tag', type=str, default='test')\n",
        "    parser.add_argument('--on_gpu', action='store_true')\n",
        "    parser.add_argument('--resume', action='store_true')\n",
        "    parser.add_argument('--batch_size', type=int, default=32)\n",
        "    parser.add_argument('--use_step_lr', action='store_true') # 調scheduler用，沒開是cyclic，打開是ms step\n",
        "    parser.add_argument('--num_workers', type=int, default=0)\n",
        "    # parser.add_argument('--window_size', type=int, default=5)\n",
        "    # 若window size為1時，在執行程式抓training set會讓rolling train day start跟end在同一天\n",
        "    parser.add_argument('--window_size', type=int, default=5)\n",
        "    parser.add_argument('--raw_dataset_path', type=str, default='.')\n",
        "    # parser.add_argument('--seed_list', type=int, nargs='+', default=[0, 1])\n",
        "    parser.add_argument('--seed_list', type=int, nargs='+', default=[0, 1])\n",
        "    # parser.add_argument('--sample_start_date', type=str, default='19960101')\n",
        "    parser.add_argument('--sample_start_date', type=str, default='20200316')\n",
        "    parser.add_argument('--sample_times', type=int, default=36)\n",
        "    # parser.add_argument('--sample_times', type=int, default=1)\n",
        "    parser.add_argument('--sample_interval', type=int, default=10)\n",
        "    #parser.add_argument('--sample_interval', type=int, default=1)\n",
        "    parser.add_argument('--n_parallel_process', type=int, default=1)\n",
        "    parser.add_argument('--model_type', type=str, default=\"multi\", choices=['multi', 'single'])\n",
        "    parser.add_argument('--daily_plot_off', action='store_true')\n",
        "    parser.add_argument('--residual_on', action='store_true')\n",
        "    parser.add_argument('--converge_delta', type=float, default=1e-5)\n",
        "    parser.add_argument('--converge_patience', type=int, default=300)\n",
        "    parser.add_argument('--master_addr', type=str, default='localhost') #主機的 IP\n",
        "    parser.add_argument('--master_port', type=str, default='16235') #主控機器開了一扇門（port）\n",
        "    # formula of rank\n",
        "    parameter = ['--on_gpu','--residual_on','--daily_plot_off','--sample_start_date', '19960101']\n",
        "    config.args = parser.parse_args(parameter)\n",
        "    #config.args = parser.parse_args()\n",
        "\n",
        "    # config.args.residual_on = True\n",
        "    # config.args.use_step_lr = True\n",
        "    print(f'Hypeparameters:{parameter}')\n",
        "    config.result_folder = f\"../{config.args.sample_start_date}_{config.args.batch_size}batchsize\"\n",
        "    if config.args.use_step_lr:\n",
        "        scheduler_setting = config.ms_step_scheduler_setting\n",
        "        config.result_folder += f\"_{'_'.join(str(lr) for lr in scheduler_setting['init_lr_list'])}initLR_{'_'.join(str(w) for w in scheduler_setting['epoch_warmup_list'])}warmup_{scheduler_setting['epoch_decay']}decaylen_{scheduler_setting['decay_times']}decaytimes_{scheduler_setting['epoch_last']}epochlast\"\n",
        "    else: # cyclical lr\n",
        "        scheduler_setting = config.cyclic_shceduler_setting\n",
        "        config.result_folder += f\"_autoLR_autoCyclen_{scheduler_setting['cur_epoch_size']}epochsize_{scheduler_setting['lr_max_to_base_ratio']}MtoBratio\"\n",
        "    config.result_folder += f\"_{scheduler_setting['gamma']}gamma_{'_'.join(str(s) for s in config.args.seed_list)}seed\"\n",
        "    config.result_folder += '_residual' if config.args.residual_on else '_multi'\n",
        "    config.result_folder += f'_{config.args.result_folder_tag}_test'\n",
        "\n",
        "    clear_files(config.args.resume, config.args.sample_start_date, config.args.model_type, config.result_folder)\n",
        "\n",
        "    print(\"To reproduce AAAI Gated-neural-networks-for-option-pricing paper results\")\n",
        "    print(config.result_folder)\n",
        "\n",
        "    # ----------Initialization---------- #\n",
        "\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "    os.environ['MASTER_ADDR'] = config.args.master_addr\n",
        "    os.environ['MASTER_PORT'] = config.args.master_port\n",
        "    data_processor = DataProcessor(root_path=config.args.raw_dataset_path, model_type='multi', sample_start_date=config.args.sample_start_date, sample_times=config.args.sample_times, sample_interval=config.args.sample_interval, on_gpu=config.args.on_gpu)\n",
        "    test_date_list, config.daily_gen, IAO_threshold = data_processor(config.args.window_size, config.args.batch_size, config.args.num_workers, config.args.n_parallel_process, config.args.residual_on, config.args.seed_list)\n",
        "    config.train_engine = TrainEngine(config.args.daily_plot_off, config.args.residual_on, config.args.use_step_lr, scheduler_setting, config.args.converge_delta, config.args.converge_patience, config.args.seed_list, IAO_threshold, config.result_folder,start_time)\n",
        "\n",
        "    # ----------For each testing date---------- #\n",
        "    if config.args.n_parallel_process == 1:\n",
        "        single_running_worker()\n",
        "\n",
        "    else:\n",
        "        multi_running_worker(test_date_list)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "    main(start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import train\n",
        "import visulization\n",
        "importlib.reload(train)\n",
        "importlib.reload(visulization)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T4lk02okzex",
        "outputId": "3c2bf344-0224-4377-800a-44fbb0ff9b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'visulization' from '/content/visulization.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(f'cpu核心數:{os.cpu_count()}')\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "def suggest_optimal_workers():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    cpu_count = os.cpu_count()\n",
        "    total_ram_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
        "\n",
        "    # 推估 num_workers：根據 CPU 和 RAM\n",
        "    if total_ram_gb >= 16 and cpu_count >= 4:\n",
        "        num_workers = min(4, cpu_count // 2)\n",
        "    elif total_ram_gb >= 8:\n",
        "        num_workers = min(2, cpu_count // 2)\n",
        "    else:\n",
        "        num_workers = 0\n",
        "\n",
        "    # 推估 n_parallel_process：根據 GPU 數量\n",
        "    if gpu_count >= 1:\n",
        "        n_parallel_process = 1  # Colab A100 為單卡，建議保守設定為 1\n",
        "    else:\n",
        "        n_parallel_process = min(2, cpu_count // 2)  # 無 GPU 時可開多進程（風險較高）\n",
        "\n",
        "    return {\n",
        "        \"gpu_count\": gpu_count,\n",
        "        \"cpu_count\": cpu_count,\n",
        "        \"total_ram_gb\": round(total_ram_gb, 2),\n",
        "        \"suggested_num_workers\": num_workers,\n",
        "        \"suggested_n_parallel_process\": n_parallel_process\n",
        "    }\n",
        "\n",
        "# 執行並印出建議\n",
        "suggestion = suggest_optimal_workers()\n",
        "for k, v in suggestion.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx2IJoFYZCcK",
        "outputId": "d7659933-2b08-48ca-f1ae-4148a0c77d15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu核心數:8\n",
            "gpu_count: 0\n",
            "cpu_count: 8\n",
            "total_ram_gb: 50.99\n",
            "suggested_num_workers: 4\n",
            "suggested_n_parallel_process: 2\n"
          ]
        }
      ]
    }
  ]
}